{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969e8a3b-4389-40c9-a331-d38449811680",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Lecturer Note**  \n",
    "This is not a data science course so we will move over the feature engineering and model training rather quickly.  \n",
    "This is also the reason for why we are using the titanic dataset and not a more \"business relevant\" dataset, such as e.g. churn prediction.  \n",
    "\n",
    "## Modelling challenge\n",
    "\n",
    "Okay we have gotten a task from the boss/client.  \n",
    "We need to predict titanic survivors using the Titanic - Machine Learning from Disaster Kaggle competition dataset.  \n",
    "Should be simple enough, we have done plenty of classification projects before.  \n",
    "Let's install the usual python packages for this sort of project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd96fe-c507-4c35-ad47-6190461c15a2",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install catboost matplotlib pandas scikit-learn kaggle optuna ipywidgets kaleido shap jupyterlab-rise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af01b9f-088b-47a6-992a-4d4902072be0",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay assuming we have set up a kaggle account and downloaded a kaggle.json token file to either .kaggle in the user directory or to the current directory in case of running in a github codespace.\n",
    "We can simply run the cell below to download titanic dataset into the data folder.  \n",
    "Alternatively just download dataset from kaggle manually.  \n",
    "Usually we have a data engineer that gives us this data and uploads to some central location that is available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63833c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../../home/vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2c5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "container_check = os.getenv(\"iscontainer\")\n",
    "if container_check==\"y\":\n",
    "    config_dir = Path(\"~/.kaggle/\")\n",
    "    config_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(config_dir / \"kaggle.json\", \"w\") as dst:\n",
    "        with open(\"./kaggle.json\", \"r\") as src:\n",
    "            dst.write(src.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6609b-85eb-4423-955b-40f599596029",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "dataset = \"titanic\"  # original competition dataset\n",
    "dataset_test = \"wesleyhowe/titanic-labelled-test-set\"  # test set augmented with target labels\n",
    "download_folder = Path(\"data/titanic\")\n",
    "zip_path = download_folder / \"titanic.zip\"\n",
    "download_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "api.competition_download_files(dataset, path=str(download_folder))\n",
    "api.dataset_download_files(dataset_test, path=str(download_folder), unzip=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(str(download_folder))\n",
    "\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3fa1a-1f8c-4307-8f41-f06cdd81ba08",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811cfdb-b7a1-4be9-ad79-cd89083ff9fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dir \"./data/titanic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63cbbe-440b-4763-a31c-094d4703661e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Perfect, so the data is in place and we can take a look at it, putting aside the PassengerId column since that is not going to be trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa42ea3-9848-4b67-a835-e244c762ccfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(download_folder / \"train.csv\")\n",
    "df_ids = df_train.pop(\"PassengerId\")  # set aside PassengerId\n",
    "\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7110ae-a746-46e7-b8cc-d765c0a6c7f5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data overview\n",
    "Okay we have been given the following data dictionary: \n",
    "\n",
    "Target is **\"Survived\"**, whether the passenger survived the sinking.  \n",
    "* **PClass**: Passenger Ticket Class, either 1, 2, 3 for 1st, 2nd, 3rd class. Categorical.\n",
    "* **Name**: Name of the passenger. Not usable raw.\n",
    "* **Sex**: Sex of the passenger. Categorical.\n",
    "* **Age**: Age of the passenger, fractional if less than 1, if estimated then in the form of xx.5. Numerical, candidate for binning into age groups.\n",
    "* **SibSp**: Number of siblings/spouses aboard. Numerical.\n",
    "* **parch**: Number of parents/children aboard. Numerical.\n",
    "* **ticket**: Ticket number. Not usable raw. Unclear if usable at all.  \n",
    "* **fare**: How much paid for the ticket. Numerical.\n",
    "* **cabin**: Cabin number. Not usable raw. \n",
    "* **embarked**: Port of embarkation, either C = Cherbourg, Q = Queenstown, S = Southampton. Categorical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfb7bc-635b-4d6e-8fe9-1f7518cc796b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And the data looks like this when it comes to missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03792ed2-14c5-45e9-a3bd-642a0fa0ded8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b746d-b03a-4dfb-a6f6-e67714c63ecb",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The cabin column is mostly null so we will drop the column.  \n",
    "Also we are not sure how to use the name since it is a string type with many, presumably all unique values, so can't just consider it a categorical value, so let's also drop that one for now.  \n",
    "Finally the ticket serial number is not usable either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554eb714-992d-4b8b-af70-bb3267af74e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9951c05-a44e-491d-902f-8d9ac4d226c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's fill nulls in embarked with the unused letter N, and fill the age nulls with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40cb01d-9c6f-4307-9b4c-a32f7edff79c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.fillna({\"Embarked\": \"N\", \"Age\": df_train[\"Age\"].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314911b-4856-4df9-a3f4-cfccafdbf1fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay now we are ready to train.  \n",
    "For model architecture we are choosing catboost, since it is the best for tabular data with a limited amount of rows,  \n",
    "and offering native support for categorical features.  \n",
    "\n",
    "We first need to define the categorical features and get their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacde22-026a-4559-9440-25ed5ba3bc5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical = [\n",
    "    \"Pclass\", \n",
    "    \"Sex\", \n",
    "    \"Embarked\"\n",
    "]\n",
    "\n",
    "y_train = df_train.pop(\"Survived\")\n",
    "X_train = df_train\n",
    "\n",
    "categorical_indices = [X_train.columns.get_loc(col) for col in categorical if col in X_train.columns]\n",
    "categorical_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7228a5-24c4-49d0-924b-26d34bbb06cb",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And verifying that there are now no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d83cc-3034-4bbb-8f60-557a0d72ad16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7db4d2-8826-4e68-ae7f-d7e77daf3311",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay now we need to choose the best parameters for training the model.  \n",
    "Using optuna to easily set up a study, with typical ranges for the parameters.  \n",
    "Then run the study and save the best parameters.  \n",
    "Also putting in an if-else to check for existing file to not run again unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c1e95-41c7-4883-9dcf-68205759d316",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "outfolder = Path(\"results\")\n",
    "outfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_params_path = outfolder / \"best_params.pkl\"\n",
    "\n",
    "if not best_params_path.is_file():\n",
    "    X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"depth\": trial.suggest_int(\"depth\", 2, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 300),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 100.0, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 1),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-5, 100.0, log=True)\n",
    "        }\n",
    "        model = CatBoostClassifier(**params, verbose=0)\n",
    "        model.fit(X_train_opt, y_train_opt, eval_set=(X_val_opt, y_val_opt), cat_features=categorical_indices, early_stopping_rounds=50)\n",
    "        return model.get_best_score()[\"validation\"][\"Logloss\"]\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    \n",
    "    joblib.dump(study.best_params, best_params_path)\n",
    "    params = study.best_params\n",
    "else:\n",
    "    params = joblib.load(best_params_path)\n",
    "print(\"Best Parameters:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23ae7a-8cf1-4c8e-9b7a-86c4efdac8b2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay now we have the optimal hyperparameters for training our model.  \n",
    "Let's train the model using cross validation to get a better idea of the performance.  \n",
    "Given the lack of data we are not setting aside a test set.  \n",
    "Setting metric to F1 to optimize both Precision and Recall and save results to file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028a79d-bfdc-42b6-a404-84579dac3a1c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params[\"eval_metric\"] = \"F1\"\n",
    "params[\"loss_function\"] = \"Logloss\"\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    **params,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "data = Pool(X_train, y_train, cat_features=categorical_indices)\n",
    "\n",
    "cv_results = cv(\n",
    "    params=params,\n",
    "    pool=data,\n",
    "    fold_count=5,\n",
    "    partition_random_seed=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "cv_results.to_csv(outfolder / \"cv_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a641895-bb58-466c-8b11-ff9eaad39bd9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's plot test performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20856f41-6fdd-4047-9b0a-52f011c85434",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add mean performance line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cv_results[\"iterations\"], y=cv_results[\"test-F1-mean\"], mode=\"lines\", name=\"Mean F1 Score\", line=dict(color=\"blue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add shaded error region\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.concat([cv_results[\"iterations\"], cv_results[\"iterations\"][::-1]]),\n",
    "        y=pd.concat([cv_results[\"test-F1-mean\"]+cv_results[\"test-F1-std\"], \n",
    "                     cv_results[\"test-F1-mean\"]-cv_results[\"test-F1-std\"]]),\n",
    "        fill=\"toself\", \n",
    "        fillcolor=\"rgba(0, 0, 255, 0.2)\",\n",
    "        line=dict(color=\"rgba(255, 255, 255, 0)\"),\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Cross-Validation (N=5) Mean F1 score with Error Bands\",\n",
    "    xaxis_title=\"Training Steps\",\n",
    "    yaxis_title=\"Performance Score\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis=dict(range=[0.5, 1])\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(outfolder / \"test_f1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf0f69-6613-436e-82b2-cdef5aec7c08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add mean performance line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cv_results[\"iterations\"], y=cv_results[\"test-Logloss-mean\"], mode=\"lines\", name=\"Mean logloss\", line=dict(color=\"blue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add shaded error region\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.concat([cv_results[\"iterations\"], cv_results[\"iterations\"][::-1]]),\n",
    "        y=pd.concat([cv_results[\"test-Logloss-mean\"]+cv_results[\"test-Logloss-std\"], \n",
    "                     cv_results[\"test-Logloss-mean\"]-cv_results[\"test-Logloss-std\"]]),\n",
    "        fill=\"toself\", \n",
    "        fillcolor=\"rgba(0, 0, 255, 0.2)\",\n",
    "        line=dict(color=\"rgba(255, 255, 255, 0)\"),\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Cross-Validation (N=5) Mean Logloss with Error Bands\",\n",
    "    xaxis_title=\"Training Steps\",\n",
    "    yaxis_title=\"Logloss\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(outfolder / \"test_logloss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b14b5-38af-449b-aa50-e98fa0867ced",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay these plots look reasonable enough, clearly we are betting than a coin-flip, so good enough for an initial model.  \n",
    "Finally we can train a model on the full dataset and performance should equal the cross validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dca52e-defa-4f93-979b-22514f11c780",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose_eval=50,\n",
    "    early_stopping_rounds=50,\n",
    "    cat_features=categorical_indices,\n",
    "    use_best_model=False,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "model.save_model(outfolder / 'catboost_model_titanic.cbm')\n",
    "joblib.dump(params, outfolder / 'model_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ee7a9-3441-4f76-a300-9d3b7367eb52",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great, that was a lot of work but now we have a trained model that is predicting better than chance saved to a model file.  \n",
    "Now let's predict on the test set and create some shapley plots to convince people that our predictions make sense!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca37953-640a-4ee6-8f2a-319cd3473272",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(download_folder / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b4439-79c5-4caa-aba8-344b13f961e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b05f3a-31e6-4734-aea4-95f4d36f94e2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Oh dear, that didnt work.  \n",
    "Right, of course we have to do all the same preprocessing again in order to also create a proper test set for prediction.  \n",
    "Let's copy the code from before but run it on the test set.  \n",
    "Dropping the unused columns again and setting aside the PassengerId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918fb09-9881-4e13-bd6d-4c4b046d809d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"])\n",
    "df_test_id = df_test.pop(\"PassengerId\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ba3ba-b88c-4e5f-a2c6-956a977f66c3",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Filling in nulls using the same placeholder for embarked and mean age (train since we need to have a certain amount of data to construct the mean from). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec9a080-7e8d-4634-a69d-d152263027e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df_test.fillna({\"Embarked\": \"N\", \"Age\": X_train[\"Age\"].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9d805-0440-446b-b09b-7dc5d5dfb85e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Making sure columns are in the right order, and then doing the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a7ee818-aa5b-4a77-94e9-d373179a70d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict(df_test[X_train.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef342f-2d43-48a8-8f53-a1d36b843f4d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Great now it works, but should we really be copy pasting code around?  \n",
    "What if we want to change the preprocessing later?  \n",
    "Anyways let's get the shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b2e23-ded8-4669-afb2-f77cbbbedec8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(df_test)\n",
    "\n",
    "shap.summary_plot(shap_values, df_test, show=False)\n",
    "plt.savefig(outfolder / \"test_shap_overall.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8069529-f637-4edc-9e24-bb52076a6830",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Okay now we have something to look at to convince ourselves that the model is making sense.  \n",
    "Finally let's save the predictions to a csv file as required by kaggle, so that we can get the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd0f930e-8ffa-4dd6-99b9-7c9d8ba6805a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[\"PassengerId\"] = df_test_id\n",
    "df_test[\"Survived\"] = preds\n",
    "df_test[[\"PassengerId\", \"Survived\"]].to_csv(outfolder / \"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79b19f-51f2-4244-9eb5-b4e289631da2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And submitting to kaggle we get the following performance which is what we would expect given our cross validation results:\n",
    "  \n",
    "![screenshot of kaggle submission page with prediction performance of 0.74880](results/kaggle_result.png \"Kaggle Result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bbc02-c85c-4639-9926-50f482c7a1ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "All done and dusted, on to the next project right?  \n",
    "Let's present to the client."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
